{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#%% md\n",
    "\n",
    "Resources of how to obtain data on GitHub\n",
    "  * [GitHub API](https://docs.github.com/en/rest)\n",
    "  * [How to create GitHub token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token#creating-a-token) or you could use this [Generate Token](https://github.com/settings/tokens/new?scopes=repo) if you do not want to read  details.\n",
    "  * Please update your github username to your name for the graphs to work and to not run into any errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake tokens. Generate your own and replace these\n",
    "token_list = [\"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\"]\n",
    "# Sample repository. Replace it with your own repository\n",
    "reponame = \"chrisj117/CS-472-GROUP-2-PROJECT\"\n",
    "ct = 0\n",
    "# Date to start collecting data from\n",
    "ignore_date = pd.to_datetime(\"2023-02-16T00:00:00-00:00\", utc=True)\n",
    "# File extensions to ignore from the graphs\n",
    "ignored_file_extensions = [\n",
    "    \".pdf\",\n",
    "    \".xml\",\n",
    "    \".html\",\n",
    "    \".css\",\n",
    "    \".log\",\n",
    "    \".txt\",\n",
    "    \".json\",\n",
    "    \".js\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@url Github API URL for extracting the\n",
    "@token_list a list of GitHub tokens\n",
    "@ct token counter\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_response(url, token_list, ct):\n",
    "    jsonData = None\n",
    "\n",
    "    len_tokens = len(token_list)\n",
    "    try:\n",
    "        ct = ct % len_tokens\n",
    "        headers = {\"Authorization\": \"Token {}\".format(token_list[ct])}\n",
    "        request = requests.get(url, headers=headers)\n",
    "        jsonData = json.loads(request.content)\n",
    "        ct += 1\n",
    "    except Exception as e:\n",
    "        ct += 1\n",
    "        print(e)\n",
    "    return jsonData, ct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This function returns the a list of contributor's names and login-names\n",
    "\n",
    "def contributors(reponame, token_list, ct):\n",
    "    contributor_names = []\n",
    "    contributor_logins = []\n",
    "    login_to_name = dict()\n",
    "\n",
    "    api = \"https://api.github.com/repos/\" + reponame + \"/contributors\"\n",
    "\n",
    "    try:\n",
    "        contributor_array, ct = get_response(api, token_list, ct)\n",
    "\n",
    "        if contributor_array is not None:\n",
    "            for contributor_obj in contributor_array:\n",
    "                contributor_name = \"\"\n",
    "                contributor_api = \"https://api.github.com/users/\" + contributor_obj[\"login\"]\n",
    "                contributor_obj2, ct = get_response(contributor_api, token_list, ct)\n",
    "                if contributor_obj2 is not None:\n",
    "                    # Exclude all the contributors with name = null in the GitHub User API\n",
    "                    if contributor_obj2[\"name\"] is not None:\n",
    "                        contributor_name = contributor_obj2[\"name\"].split(\" \")[0]\n",
    "                        login_to_name[contributor_obj[\"login\"]] = contributor_name\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return login_to_name, ct\n",
    "\n",
    "\n",
    "login_to_name, ct = contributors(reponame, token_list, ct)\n",
    "print(login_to_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This function takes in the contributor list returned in the\n",
    "# previous cell\n",
    "\n",
    "\n",
    "def pullrequest_details(reponame, login_to_name, token_list, ct):\n",
    "    contributor_pr_count = dict()\n",
    "    contributor_pr_review_count = dict()\n",
    "    contributor_changedFiles_count = dict()\n",
    "    contributor_changedLOC = dict()\n",
    "\n",
    "    try:\n",
    "        # loop though all the commit pages until the last returned empty page\n",
    "        ipage = 1\n",
    "        while True:\n",
    "            spage = str(ipage)\n",
    "            pr_api = \"https://api.github.com/repos/\" + reponame + \"/pulls?page=\" + spage + \"&per_page=100&state=closed\"\n",
    "            pr_list, ct = get_response(pr_api, token_list, ct)\n",
    "\n",
    "            # break out of the while loop if there are no more commits in the pages\n",
    "            if len(pr_list) == 0:\n",
    "                break\n",
    "\n",
    "            # iterate through the list of pull requests in page\n",
    "            for pr_obj in pr_list:\n",
    "                pr_number = pr_obj[\"number\"]\n",
    "                login = pr_obj[\"user\"][\"login\"]\n",
    "                contri_name = login_to_name[login]\n",
    "\n",
    "                # Only count PRs that were merged\n",
    "                if pr_obj[\"merged_at\"] is not None:\n",
    "                    merged_at = pr_obj[\"merged_at\"]\n",
    "\n",
    "                    date1 = pd.to_datetime(merged_at, utc=True)\n",
    "                    difference = date1 - ignore_date\n",
    "                    difference = difference.total_seconds() // 3600\n",
    "\n",
    "                    # Only count PRs that were merged after the ignore_date\n",
    "                    if difference > 0:\n",
    "\n",
    "                        # Increase contributor's PR count\n",
    "                        contributor_pr_count[contri_name] = contributor_pr_count.get(contri_name, 0) + 1\n",
    "\n",
    "                        # Print the title of the PR (for debugging)\n",
    "                        # print(pr_obj['title'])\n",
    "\n",
    "                        \"\"\"\n",
    "                            We want to identify the authors of each chached file in the PR. First, we \n",
    "                            shall collect a list of PR-files and list of PR-commits. Second, we iterate\n",
    "                            through a list of commits and pick the files changed in each commit and identify\n",
    "                            the commit author as well as the files they changed. Lastly, we compare the files \n",
    "                            in the commits and those in PR-files and assign them to the different authors. \n",
    "                            \"\"\"\n",
    "\n",
    "                        # we only care about changed files in a PR, not the individual commits\n",
    "                        pr_changedFiles_api = \"https://api.github.com/repos/\" + reponame + \"/pulls/\" + str(pr_number) + \"/files\"\n",
    "                        pr_changedFiles_list, ct = get_response(pr_changedFiles_api, token_list, ct)\n",
    "\n",
    "                        # Add the number of changed files to the contributor's count and lines of code changed\n",
    "                        for file_obj1 in pr_changedFiles_list:\n",
    "                            file = file_obj1[\"filename\"]\n",
    "\n",
    "                            # if file does not end with any of the ignored file extensions (declared above),\n",
    "                            # add it to the LOC count & changed files count\n",
    "                            if not any(file.endswith(x) for x in ignored_file_extensions):\n",
    "\n",
    "                                # A note about the changed files, it does not track unique files,\n",
    "                                # but rather the number of files changed in a PR irregardless if they already changed them before or not.\n",
    "                                contributor_changedFiles_count[contri_name] = contributor_changedFiles_count.get(contri_name, 0) + 1\n",
    "\n",
    "                                contributor_changedLOC[contri_name] = contributor_changedLOC.get(contri_name, 0) + file_obj1[\"changes\"]\n",
    "\n",
    "                                # Optional print statement to see the files and LOC changed by each contributor\n",
    "                                # print(contri_name + \" \" + str(file) + \" \" + str(file_obj1['changes']) + \" \" + str( contributor_changedLOC.get(contri_name, 0)))\n",
    "\n",
    "                        pr_reviews_api = \"https://api.github.com/repos/\" + reponame + \"/pulls/\" + str(pr_number) + \"/reviews?per_page=100\"\n",
    "\n",
    "                        pr_reviews_list, ct = get_response(pr_reviews_api, token_list, ct)\n",
    "\n",
    "                        # Check if we have already counted a reviewer\n",
    "                        # This is to ensure that people that just commented on a PR receive proper credit\n",
    "                        # Even if they have not approved the PR.\n",
    "                        already_reviewed = set()\n",
    "                        if len(pr_reviews_list) != 0:\n",
    "                            for pr_review_obj in pr_reviews_list:\n",
    "                                login = pr_review_obj[\"user\"][\"login\"]\n",
    "                                # Ignore someone commenting that isnt apart of our group\n",
    "                                if login not in login_to_name.keys():\n",
    "                                    continue\n",
    "                                reviewer_name = login_to_name[login]\n",
    "                                if reviewer_name is not contri_name and reviewer_name not in already_reviewed:\n",
    "                                    already_reviewed.add(reviewer_name)\n",
    "                                    # print(\"Reviewed By: \" + reviewer_name)\n",
    "                                    contributor_pr_review_count[reviewer_name] = contributor_pr_review_count.get(reviewer_name, 0) + 1\n",
    "\n",
    "            ipage += 1\n",
    "    except Exception as e:\n",
    "        print(\"Error receiving data\")\n",
    "        print(e)\n",
    "\n",
    "    return (\n",
    "        contributor_pr_count,\n",
    "        contributor_pr_review_count,\n",
    "        contributor_changedFiles_count,\n",
    "        contributor_changedLOC,\n",
    "        ct,\n",
    "    )\n",
    "\n",
    "\n",
    "(\n",
    "    contributor_pr_count,\n",
    "    contributor_pr_review_count,\n",
    "    contributor_changedFiles_count,\n",
    "    contributor_changedLOC,\n",
    "    ct,\n",
    ") = pullrequest_details(reponame, login_to_name, token_list, ct)\n",
    "\n",
    "print(\"contributor_pr_count\", contributor_pr_count)\n",
    "print(\"contributor_pr_review_count\", contributor_pr_review_count)\n",
    "print(\"contributor_changedFiles_count\", contributor_changedFiles_count)\n",
    "print(\"contributor_changedLOC\", contributor_changedLOC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This function processes the issue details of a repository\n",
    "def issue_details(reponame, login_to_name, token_list, ct):\n",
    "    contributor_issue_count = dict()\n",
    "    contributor_comment_count = dict()\n",
    "\n",
    "    try:\n",
    "        # loop though all the commit pages until the last returned empty page\n",
    "        ipage = 1\n",
    "        while True:\n",
    "            spage = str(ipage)\n",
    "            issue_api = \"https://api.github.com/repos/\" + reponame + \"/issues?page=\" + spage + \"&per_page=100&state=all\"\n",
    "            issue_array, ct = get_response(issue_api, token_list, ct)\n",
    "\n",
    "            # break out of the while loop if there are no more commits in the pages\n",
    "            if len(issue_array) == 0:\n",
    "                # print(\"no issues\", issue_api)\n",
    "                break\n",
    "\n",
    "            # iterate through the list of issues and colloect the issue contributors\n",
    "            for issue_obj in issue_array:\n",
    "\n",
    "                date1 = pd.to_datetime(issue_obj[\"created_at\"], utc=True)\n",
    "                difference = date1 - ignore_date\n",
    "                difference = difference.total_seconds() // 3600\n",
    "\n",
    "                if \"pull_request\" not in issue_obj.keys() and difference > 0:\n",
    "\n",
    "                    login = issue_obj[\"user\"][\"login\"]\n",
    "                    contri_name = login_to_name[login]\n",
    "\n",
    "                    # Original creator of the issue\n",
    "                    contributor_issue_count[contri_name] = contributor_issue_count.get(contri_name, 0) + 1\n",
    "\n",
    "                    # Add the number of comments to the collection array\n",
    "                    issue_comments_api = issue_obj[\"comments_url\"]\n",
    "                    issue_comment_array, ct = get_response(issue_comments_api, token_list, ct)\n",
    "                    if len(issue_comment_array) != 0:\n",
    "                        for issue_comment_obj in issue_comment_array:\n",
    "                            commenter_login = issue_comment_obj[\"user\"][\"login\"]\n",
    "                            commentor_name = login_to_name[commenter_login]\n",
    "                            contributor_comment_count[commentor_name] = contributor_comment_count.get(commentor_name, 0) + 1\n",
    "\n",
    "            ipage += 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Error receiving data\")\n",
    "\n",
    "    return contributor_issue_count, contributor_comment_count, ct\n",
    "\n",
    "\n",
    "contributor_issue_count, contributor_comment_count, ct = issue_details(reponame, login_to_name, token_list, ct)\n",
    "\n",
    "print(\"contributor_issue_count\", contributor_issue_count)\n",
    "print(\"contributor_comment_count\", contributor_comment_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_pr = pd.DataFrame(contributor_pr_count.items(), columns=[\"Login\", \"PRs\"])\n",
    "df_prReviews = pd.DataFrame(contributor_pr_review_count.items(), columns=[\"Login\", \"PR_Reviews\"])\n",
    "df_pr_ChangedFiles = pd.DataFrame(contributor_changedFiles_count.items(), columns=[\"Login\", \"Changed_Files\"])\n",
    "df_pr_ChangedLOC = pd.DataFrame(contributor_changedLOC.items(), columns=[\"Login\", \"Changed_LOC\"])\n",
    "df_issues = pd.DataFrame(contributor_issue_count.items(), columns=[\"Login\", \"Issues\"])\n",
    "df_issues_comments = pd.DataFrame(contributor_comment_count.items(), columns=[\"Login\", \"Issue_Comments\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "df_list = [\n",
    "    df_pr,\n",
    "    df_prReviews,\n",
    "    df_issues,\n",
    "    df_issues_comments,\n",
    "    df_pr_ChangedFiles,\n",
    "    df_pr_ChangedLOC,\n",
    "]\n",
    "df_merged = reduce(lambda left, right: pd.merge(left, right, on=[\"Login\"], how=\"outer\"), df_list)\n",
    "df_merged = df_merged.fillna(0).sort_values(\"Changed_LOC\", ascending=[0])\n",
    "df_merged = df_merged.head(25)\n",
    "df_merged.sort_index(inplace=True)\n",
    "df_merged = df_merged.head(13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Replace the login names with your real names in the report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.style.use(\"classic\")\n",
    "ax = df_merged.plot(x=\"Login\", y=[\"PRs\", \"PR_Reviews\", \"Issues\", \"Issue_Comments\"], kind=\"bar\", rot=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig('../img/contributions.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"classic\")\n",
    "ax = df_merged.plot(x=\"Login\", y=[\"Changed_Files\"], kind=\"bar\", rot=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.style.use(\"classic\")\n",
    "ax = df_merged.plot(x=\"Login\", y=[\"Changed_LOC\"], kind=\"bar\", rot=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
